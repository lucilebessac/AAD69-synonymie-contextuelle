# √âtude historique et comparative de diff√©rentes m√©thodes de s√©mantique distributionnelle sur la base d‚Äôun corpus ParlaMint

Ce projet propose **trois m√©thodes distinctes** de s√©mantique distributionnelle sur la base d‚Äôun corpus ParlaMint

1. **üß† Approche Word2Vec** : Analyse distributionnelle classique avec clustering
2. **üîç Approche Syntaxique (GrewPy)** : Extraction d'√©nonc√©s √©l√©mentaires par motifs syntaxiques
3. **üßÆ Approche de Cooccurrence** : Matrice de Cooccurrence (DSM) en R Studio

---

## üß† Analyse s√©mantique avec Word2Vec

Cette approche utilise les **repr√©sentations vectorielles distribu√©es** pour identifier des regroupements s√©mantiques dans le vocabulaire parlementaire.

### üìå Objectifs
* Apprendre des repr√©sentations vectorielles distribu√©es pour les mots du corpus
* R√©duire la dimension pour faciliter l'exploration visuelle
* Identifier des regroupements s√©mantiques via clustering hi√©rarchique
* Extraire des mots repr√©sentatifs et sp√©cifiques pour chaque cluster (repr√©sentants et parangons)

### üîÅ Pipeline des scripts (ordre d'ex√©cution)
1. **Pr√©traitement du corpus** ‚Üí `02_preprocess.py`  
   Nettoyage du texte, lemmatisation, suppression des stopwords
2. **Construction des bigrammes** ‚Üí `03_bigramm.py`  
   Identification des expressions fr√©quentes pour enrichir le contexte
3. **Entra√Ænement du mod√®le Word2Vec** ‚Üí `04_train_word2vec.py`  
   Mod√®le entra√Æn√© en Skip-gram avec Gensim
4. **R√©duction de dimension (PCA)** ‚Üí `05_reduce_dimensions.py`  
   R√©duction √† 20 dimensions (pour clustering), puis 2D (visualisation)
5. **Clusterisation hi√©rarchique (Ward, k=10)** ‚Üí `Ward_clustering.py`  
   Attribution d'un cluster √† chaque mot selon la m√©thode de Ward
6. **Visualisation des clusters (k=10)** ‚Üí `07_Ward_visualization.py`  
   Projection 2D par PCA, mots color√©s selon leur cluster
7. **Dendrogramme hi√©rarchique** ‚Üí `08_dindogramme.py`  
   Repr√©sentation arborescente des fusions de clusters
8. **M√©thode du coude (inertie intra-classe)** ‚Üí `09_marches_d'inertie.py`  
   Aide √† identifier un nombre optimal de clusters
9. **Clusterisation alternative (k=3)** ‚Üí `10_Ward_clustering_k=3.py`  
   R√©duction de granularit√© pour plus de lisibilit√© th√©matique
10. **Visualisation (Ward, k=3)** ‚Üí `11_Ward_visualisation_k=3.py`
11. **Extraction des repr√©sentants et parangons** ‚Üí `12_repr√©senatants_parangons.py`  
    Calcul des mots typiques et sp√©cifiques √† chaque cluster

### üìÇ Donn√©es produites
* `word2vec.model` ‚Äî mod√®le Word2Vec entra√Æn√©
* `X_reduced.npy` ‚Äî vecteurs Word2Vec r√©duits (20D)
* `words.pkl` ‚Äî liste des mots align√©s avec `X_reduced`
* `mots_clusters_ward.csv` ‚Äî affectation des mots aux clusters
* `representants_parangons_k3.csv` ‚Äî mots typiques et discriminants par cluster

### üìä Visualisations Word2Vec
* `clusters_ward_pca.png` ‚Äî Projection 2D des clusters (k=10)
* `dendrogramme_ward.png` ‚Äî Dendrogramme hi√©rarchique (Ward)
* `inertie_dendrogramme_coude.png` ‚Äî M√©thode du coude (inertie vs. k)
* `clusters_k3.png` ‚Äî Clusters r√©duits √† k=3
* `repr√©sentants.png` ‚Äî Mots proches du centro√Øde (repr√©sentants)
* `parangons.png` ‚Äî Mots les plus sp√©cifiques par cluster

---

## Approche Syntaxique avec GrewPy

Cette approche se concentre sur l'**extraction d'√©nonc√©s √©l√©mentaires** bas√©e sur des motifs syntaxiques sp√©cifiques.

### üìå Objectifs
* Extraire automatiquement les √©nonc√©s √©l√©mentaires du corpus ParlaMint 2018
* Identifier les structures syntaxiques r√©currentes (D√©terminant-Nom-Auxiliaire-Verbe)
* G√©n√©rer des fichiers CoNLL pour l'analyse syntaxique
* Indexer et filtrer les √©nonc√©s selon des crit√®res linguistiques

### Pipeline syntaxique
1. **G√©n√©ration CoNLL** ‚Üí `generate_conll()`  
   Conversion du corpus textuel en format CoNLL via Stanza
2. **Chargement du corpus** ‚Üí `grewpy.Corpus()`  
   Chargement des fichiers CoNLL pour l'analyse syntaxique
3. **Recherche de motifs** ‚Üí Pattern matching avec GrewPy  
   ```
   pattern {
       X-[nsubj|obj|iobj|nsubj:pass|cop]->Y;
       Y-[det]->Z;
       X-[aux:pass|aux:tense]->W;
   }
   ```
4. **Indexation** ‚Üí `indexe_enonces_elem()`  
   Extraction des formes lemmatis√©es (D1, N1, AUX, V)
5. **Export** ‚Üí G√©n√©ration du fichier `enonces_elementaires.txt`

### Donn√©es produites (GrewPy)
* `*.conll` ‚Äî Fichiers d'analyse syntaxique (format CoNLL-U)
* `enonces_elementaires.txt` ‚Äî √ânonc√©s extraits sous forme textuelle
* Structure index√©e des √©nonc√©s avec m√©tadonn√©es linguistiques

### Scripts utilitaires
* **Renum√©rotation des sent_id** ‚Äî Script pour harmoniser l'indexation des phrases dans les fichiers CoNLL

---

## üßÆ Approche de Cooccurrence** : Matrice de Cooccurrence (DSM) en R Studio

Cette m√©thode s‚Äôappuie sur une matrice de cooccurrences pond√©r√©e par PPMI.

### üìå Objectifs
* Nettoyer et tokeniser les fichiers du corpus ParlaMint
* Construire une matrice creuse de cooccurrence (DSM)
* Appliquer le score PPMI (Positive Pointwise Mutual Information)
* R√©duire la dimension via MDS ou PCA
* Identifier des groupes s√©mantiques par k-means
* Visualiser l‚Äôespace s√©mantique en 2D

### üîÅ Pipeline des scripts (ordre d‚Äôex√©cution)
1. **Lecture des fichiers du corpus**
   Chargement de fichiers .txt, suppression des lignes vides et du bruit typographique
2. **Tokenisation + nettoyage**
   Mise en minuscules, suppression de ponctuation, mots courts, stopwords
3. **Extraction des cooccurrences** (fen√™tre glissante)
   Cr√©ation de triplets (mot, contexte, poids)
4. **Construction de la matrice DSM**
   Matrice terme x contexte au format creux (Matrix::sparseMatrix)
5. **Pond√©ration avec PPMI**
   Transformation des cooccurrences brutes en scores informatifs
6. **R√©duction de dimension (MDS ou PCA)**
   Projection 2D pour visualisation
7. **Clusterisation par k-means**
   Identification de groupes lexicaux
8. **Visualisation finale**
   Repr√©sentation graphique avec factoextra::fviz_cluster()

üìÇ Donn√©es produites
* dsm_ppmi ‚Äî Matrice DSM (terme x contexte) pond√©r√©e par PPMI
* coords_kmeans ‚Äî Coordonn√©es MDS des mots pour affichage
* mat_top ‚Äî Matrice dense r√©duite aux mots les plus fr√©quents
* clustering$cluster ‚Äî Affectation des mots aux clusters
* Graphiques g√©n√©r√©s : clustering par MDS et PCA

## Installation et D√©pendances

### D√©pendances communes
```bash
pip install -r requirements.txt
```

### Approche Word2Vec
* `gensim`
* `numpy` (recommand√© : version 1.24.x pour compatibilit√© Gensim)
* `pandas`
* `scikit-learn`
* `matplotlib`
* `seaborn`

### Approche GrewPy
* `grewpy` (‚â•0.4.0)
* `spacy-conll` (‚â•1.4.0)
* `stanza` (‚â•1.4.0)
* `torch` (‚â•1.9.0)
* `numpy` (‚â•1.21.0)

### Approche de Cooccurrence
* installer ces biblioth√®ques sur R
  ```
  install.packages(c(
  "wordspace", 
  "stopwords", 
  "Matrix", 
  "factoextra"))
```
